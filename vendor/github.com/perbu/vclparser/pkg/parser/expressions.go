package parser

import (
	"fmt"
	"strconv"
	"strings"

	ast2 "github.com/perbu/vclparser/pkg/ast"
	"github.com/perbu/vclparser/pkg/lexer"
)

// Operator precedence levels
const (
	_ int = iota
	LOWEST
	LOGICAL_OR  // ||
	LOGICAL_AND // &&
	EQUALITY    // ==, !=
	COMPARISON  // <, >, <=, >=
	REGEX       // ~, !~
	TERM        // +, -
	FACTOR      // *, /, %
	UNARY       // !, -, +
	CALL        // function()
	INDEX       // array[index]
	MEMBER      // obj.prop
)

// Precedence map for operators
var precedences = map[lexer.TokenType]int{
	lexer.COR:      LOGICAL_OR,
	lexer.CAND:     LOGICAL_AND,
	lexer.EQ:       EQUALITY,
	lexer.NEQ:      EQUALITY,
	lexer.LT:       COMPARISON,
	lexer.GT:       COMPARISON,
	lexer.LEQ:      COMPARISON,
	lexer.GEQ:      COMPARISON,
	lexer.TILDE:    REGEX,
	lexer.NOMATCH:  REGEX,
	lexer.PLUS:     TERM,
	lexer.MINUS:    TERM,
	lexer.MULTIPLY: FACTOR,
	lexer.DIVIDE:   FACTOR,
	lexer.PERCENT:  FACTOR,
	lexer.LPAREN:   CALL,
	lexer.DOT:      MEMBER,
}

// peekPrecedence returns the precedence of the peek token
func (p *Parser) peekPrecedence() int {
	if p, ok := precedences[p.peekToken.Type]; ok {
		return p
	}
	return LOWEST
}

// currentPrecedence returns the precedence of the current token
func (p *Parser) currentPrecedence() int {
	if p, ok := precedences[p.currentToken.Type]; ok {
		return p
	}
	return LOWEST
}

// parseExpression parses expressions using Pratt parsing
func (p *Parser) parseExpression() ast2.Expression {
	return p.parseExpressionWithPrecedence(LOWEST)
}

// parseExpressionWithPrecedence implements a Pratt parser (top-down operator precedence parser)
// using the precedence climbing algorithm. This approach elegantly handles operator precedence
// without deep recursion or backtracking.
//
// The algorithm works by:
// 1. Parse a prefix expression (operand, unary operator, etc.)
// 2. Enter a loop that continues while the next operator has higher precedence than our minimum
// 3. Parse the infix expression (consuming the operator and right operand)
// 4. The right operand parsing respects precedence through recursive calls
//
// Example parsing "a + b * c":
// - Start with precedence=LOWEST, parse "a" as left operand
// - See "+", its precedence (TERM) > LOWEST, so enter loop
// - Parse infix: parseInfixExpression creates BinaryExpression(a, +, right)
// - To parse right side of +, call parseExpressionWithPrecedence(TERM+1)
// - Parse "b", see "*", its precedence (FACTOR) > TERM+1, so enter nested loop
// - Result: BinaryExpression(a, +, BinaryExpression(b, *, c))
//
// The precedence parameter acts as "left-binding power" - operators with higher
// precedence than this value will be consumed by this call, while lower precedence
// operators are left for parent calls to handle.
//
// Termination conditions check for syntactic boundaries where expressions end:
// semicolons (statement end), parentheses/braces (grouping end), commas (argument separator).
func (p *Parser) parseExpressionWithPrecedence(precedence int) ast2.Expression {
	if p.maxErrorsReached {
		return &ast2.ErrorExpression{
			BaseNode: ast2.BaseNode{
				StartPos: p.currentToken.Start,
				EndPos:   p.currentToken.End,
			},
			Message: "max errors reached",
		}
	}

	if p.panicMode {
		p.skipToSynchronizationPoint(
			lexer.SEMICOLON, lexer.COMMA, lexer.RPAREN,
			lexer.RBRACE, lexer.CAND, lexer.COR,
		)
		p.synchronize()
		return &ast2.ErrorExpression{
			BaseNode: ast2.BaseNode{
				StartPos: p.currentToken.Start,
				EndPos:   p.currentToken.End,
			},
			Message: "expression recovery",
		}
	}

	left := p.parsePrefixExpression()
	if left == nil {
		return nil
	}

	for !p.peekTokenIs(lexer.SEMICOLON) && !p.peekTokenIs(lexer.RPAREN) &&
		!p.peekTokenIs(lexer.RBRACE) && !p.peekTokenIs(lexer.COMMA) &&
		precedence < p.peekPrecedence() {
		if left == nil {
			break
		}
		left = p.parseInfixExpression(left)
		if left == nil {
			return nil
		}
	}

	return left
}

// parsePrefixExpression parses prefix expressions
func (p *Parser) parsePrefixExpression() ast2.Expression {
	switch p.currentToken.Type {
	case lexer.ID:
		return p.parseIdentifier()
	// Keywords can also be used as identifiers in some contexts
	case lexer.HASH_KW, lexer.PASS_KW, lexer.PIPE_KW, lexer.FETCH_KW,
		lexer.HIT_KW, lexer.MISS_KW, lexer.DELIVER_KW, lexer.PURGE_KW,
		lexer.SYNTH_KW, lexer.ABANDON_KW, lexer.RETRY_KW, lexer.OK_KW, lexer.FAIL_KW,
		lexer.ERROR_KW, lexer.RESTART_KW, lexer.ACL_KW, lexer.LOOKUP_KW, lexer.VCL_KW:
		return &ast2.Identifier{
			BaseNode: ast2.BaseNode{
				StartPos: p.currentToken.Start,
				EndPos:   p.currentToken.End,
			},
			Name: p.currentToken.Value,
		}
	case lexer.CNUM:
		// Check if this number is followed by a time unit (like "30s")
		if p.isNumberFollowedByTimeUnit() {
			return p.parseTimeExpressionFromNumber()
		}
		return p.parseIntegerLiteral()
	case lexer.FNUM:
		// Check if this float number is followed by a time unit (like "1.5s")
		if p.isNumberFollowedByTimeUnit() {
			return p.parseTimeExpressionFromNumber()
		}
		return p.parseFloatLiteral()
	case lexer.CSTR:
		return p.parseStringLiteral()
	case lexer.LSTR:
		return p.parseLongStringLiteral()
	case lexer.BANG, lexer.MINUS, lexer.PLUS:
		return p.parseUnaryExpression()
	case lexer.LPAREN:
		return p.parseGroupedExpression()
	case lexer.LBRACE:
		return p.parseObjectExpression()
	default:
		// Try to parse as time/duration/IP literal
		if p.isTimeOrDurationLiteral() {
			return p.parseTimeExpression()
		}
		if p.isIPLiteral() {
			return p.parseIPExpression()
		}

		p.addError("unexpected token in expression: " + p.currentToken.Type.String())
		return nil
	}
}

// parseInfixExpression parses infix expressions
func (p *Parser) parseInfixExpression(left ast2.Expression) ast2.Expression {
	switch p.peekToken.Type {
	case lexer.COR, lexer.CAND, lexer.EQ, lexer.NEQ, lexer.LT, lexer.GT,
		lexer.LEQ, lexer.GEQ, lexer.PLUS, lexer.MINUS, lexer.MULTIPLY,
		lexer.DIVIDE, lexer.PERCENT:
		return p.parseBinaryExpression(left)
	case lexer.TILDE, lexer.NOMATCH:
		return p.parseRegexMatchExpression(left)
	case lexer.LPAREN:
		return p.parseCallExpression(left)
	case lexer.DOT:
		return p.parseMemberExpression(left)
	default:
		return left
	}
}

// parseIdentifier parses an identifier
func (p *Parser) parseIdentifier() *ast2.Identifier {
	return &ast2.Identifier{
		BaseNode: ast2.BaseNode{
			StartPos: p.currentToken.Start,
			EndPos:   p.currentToken.End,
		},
		Name: p.currentToken.Value,
	}
}

// parseIntegerLiteral parses an integer literal
func (p *Parser) parseIntegerLiteral() *ast2.IntegerLiteral {
	value, err := strconv.ParseInt(p.currentToken.Value, 0, 64)
	if err != nil {
		p.addError("could not parse " + p.currentToken.Value + " as integer")
		return nil
	}

	return &ast2.IntegerLiteral{
		BaseNode: ast2.BaseNode{
			StartPos: p.currentToken.Start,
			EndPos:   p.currentToken.End,
		},
		Value: value,
	}
}

// parseFloatLiteral parses a float literal
func (p *Parser) parseFloatLiteral() *ast2.FloatLiteral {
	value, err := strconv.ParseFloat(p.currentToken.Value, 64)
	if err != nil {
		p.addError("could not parse " + p.currentToken.Value + " as float")
		return nil
	}

	return &ast2.FloatLiteral{
		BaseNode: ast2.BaseNode{
			StartPos: p.currentToken.Start,
			EndPos:   p.currentToken.End,
		},
		Value: value,
	}
}

// parseStringLiteral parses a string literal
func (p *Parser) parseStringLiteral() *ast2.StringLiteral {
	// Remove quotes from string literal
	value := strings.Trim(p.currentToken.Value, `"`)

	return &ast2.StringLiteral{
		BaseNode: ast2.BaseNode{
			StartPos: p.currentToken.Start,
			EndPos:   p.currentToken.End,
		},
		Value: value,
	}
}

// parseLongStringLiteral parses a long string literal ({" ... "})
func (p *Parser) parseLongStringLiteral() *ast2.StringLiteral {
	// Remove {" and "} delimiters from long string literal
	value := p.currentToken.Value
	if strings.HasPrefix(value, `{"`) && strings.HasSuffix(value, `"}`) {
		value = value[2 : len(value)-2]
	}

	return &ast2.StringLiteral{
		BaseNode: ast2.BaseNode{
			StartPos: p.currentToken.Start,
			EndPos:   p.currentToken.End,
		},
		Value: value,
	}
}

// parseUnaryExpression parses a unary expression
func (p *Parser) parseUnaryExpression() *ast2.UnaryExpression {
	expr := &ast2.UnaryExpression{
		BaseNode: ast2.BaseNode{
			StartPos: p.currentToken.Start,
		},
		Operator: p.currentToken.Value,
	}

	p.nextToken() // move past operator
	expr.Operand = p.parseExpressionWithPrecedence(UNARY)
	expr.EndPos = p.currentToken.End

	return expr
}

// parseGroupedExpression parses a parenthesized expression
func (p *Parser) parseGroupedExpression() *ast2.ParenthesizedExpression {
	expr := &ast2.ParenthesizedExpression{
		BaseNode: ast2.BaseNode{
			StartPos: p.currentToken.Start,
		},
	}

	p.nextToken() // move past '('
	expr.Expression = p.parseExpression()

	if !p.expectPeek(lexer.RPAREN) {
		return nil
	}

	expr.EndPos = p.currentToken.End
	return expr
}

// parseBinaryExpression parses a binary expression
func (p *Parser) parseBinaryExpression(left ast2.Expression) *ast2.BinaryExpression {
	if left == nil {
		p.addError("left expression is nil")
		return nil
	}

	expr := &ast2.BinaryExpression{
		BaseNode: ast2.BaseNode{
			StartPos: left.Start(),
		},
		Left: left,
	}

	precedence := p.currentPrecedence()
	p.nextToken() // move to operator
	expr.Operator = p.currentToken.Value
	p.nextToken() // move past operator

	expr.Right = p.parseExpressionWithPrecedence(precedence)
	expr.EndPos = p.currentToken.End

	return expr
}

// parseRegexMatchExpression parses regex match expressions
func (p *Parser) parseRegexMatchExpression(left ast2.Expression) *ast2.RegexMatchExpression {
	expr := &ast2.RegexMatchExpression{
		BaseNode: ast2.BaseNode{
			StartPos: left.Start(),
		},
		Left: left,
	}

	p.nextToken() // move to operator
	expr.Operator = p.currentToken.Value
	p.nextToken() // move past operator

	expr.Right = p.parseExpressionWithPrecedence(REGEX)
	expr.EndPos = p.currentToken.End

	return expr
}

// parseCallExpression parses a function call expression with support for both
// positional and named arguments. Uses two-phase parsing: first collects all
// positional arguments, then processes named arguments (name=value pairs).
// Validates against duplicate named arguments and maintains VCL compatibility.
func (p *Parser) parseCallExpression(fn ast2.Expression) *ast2.CallExpression {
	if fn == nil {
		p.addError("function expression is nil")
		return nil
	}

	expr := &ast2.CallExpression{
		BaseNode: ast2.BaseNode{
			StartPos: fn.Start(),
		},
		Function:       fn,
		NamedArguments: make(map[string]ast2.Expression),
	}

	p.nextToken() // move to '('

	// Handle arguments if present
	if !p.peekTokenIs(lexer.RPAREN) {
		p.nextToken() // move past '(' to the first argument's token

		// Phase 1: Parse positional arguments until we see "name =" pattern
		for !p.currentTokenIs(lexer.RPAREN) {
			// Check if this is the start of named arguments (ID followed by =)
			if p.isNamedArgument() {
				break
			}

			// Parse positional argument
			arg := p.parseExpression()
			if arg == nil {
				p.addError("failed to parse function argument")
				return nil
			}
			expr.Arguments = append(expr.Arguments, arg)

			// Break if we hit closing paren or check for comma
			if p.peekTokenIs(lexer.RPAREN) {
				break
			}
			if !p.peekTokenIs(lexer.COMMA) {
				p.addError("expected ',' or ')' after function argument")
				return nil
			}
			p.nextToken() // move to ','
			p.nextToken() // move past ','
		}

		// Phase 2: Parse named arguments
		// Named parameters can use keywords as names (e.g., probe=, backend=, port=)
		for (p.currentTokenIs(lexer.ID) || p.isKeywordToken(p.currentToken.Type)) && p.peekTokenIs(lexer.ASSIGN) {
			// Parse named argument
			argName := p.currentToken.Value
			p.nextToken() // move to '='
			p.nextToken() // move past '='

			// Check for duplicate named argument
			if _, exists := expr.NamedArguments[argName]; exists {
				p.addError(fmt.Sprintf("argument '%s' already used", argName))
				return nil
			}

			arg := p.parseExpression()
			if arg == nil {
				p.addError("failed to parse named argument value")
				return nil
			}
			expr.NamedArguments[argName] = arg

			// Break if we hit closing paren or check for comma
			if p.peekTokenIs(lexer.RPAREN) {
				break
			}
			if !p.peekTokenIs(lexer.COMMA) {
				p.addError("expected ',' or ')' after named argument")
				return nil
			}
			p.nextToken() // move to ','
			p.nextToken() // move past ','
		}
	}

	// After parsing arguments, we MUST find and consume the closing parenthesis
	if !p.expectPeek(lexer.RPAREN) {
		return nil
	}

	expr.EndPos = p.currentToken.End
	return expr
}

// parseMemberExpression parses member access expressions
func (p *Parser) parseMemberExpression(obj ast2.Expression) *ast2.MemberExpression {
	expr := &ast2.MemberExpression{
		BaseNode: ast2.BaseNode{
			StartPos: obj.Start(),
		},
		Object: obj,
	}

	p.nextToken() // move to '.'
	p.nextToken() // move past '.'

	// Since the lexer now supports hyphens in identifiers natively,
	// we can just parse as a regular identifier
	expr.Property = p.parseIdentifier()
	expr.EndPos = p.currentToken.End

	return expr
}

// isKeywordToken checks if a token type is a VCL keyword
// Keywords can appear as part of HTTP header names
func (p *Parser) isKeywordToken(tokenType lexer.TokenType) bool {
	switch tokenType {
	case lexer.BACKEND_KW, lexer.PROBE_KW, lexer.ACL_KW, lexer.SUB_KW,
		lexer.IF_KW, lexer.ELSE_KW, lexer.ELSIF_KW, lexer.ELSEIF_KW, lexer.ELIF_KW,
		lexer.SET_KW, lexer.UNSET_KW, lexer.INCLUDE_KW,
		lexer.IMPORT_KW, lexer.RETURN_KW, lexer.CALL_KW,
		lexer.HASH_KW, lexer.PASS_KW, lexer.PIPE_KW, lexer.FETCH_KW,
		lexer.HIT_KW, lexer.MISS_KW, lexer.DELIVER_KW, lexer.PURGE_KW,
		lexer.SYNTH_KW, lexer.SYNTHETIC_KW, lexer.ABANDON_KW, lexer.RETRY_KW,
		lexer.OK_KW, lexer.FAIL_KW, lexer.ERROR_KW, lexer.RESTART_KW,
		lexer.LOOKUP_KW, lexer.VCL_KW, lexer.NEW_KW:
		return true
	}
	return false
}

// isNumberToken checks if a token type is a number
// Numbers can appear as part of HTTP header names (e.g., X-1, timestamp-2)
func (p *Parser) isNumberToken(tokenType lexer.TokenType) bool {
	return tokenType == lexer.CNUM || tokenType == lexer.FNUM
}

// parsePropertyValue parses a property value in an object expression
// VCL allows implicit string concatenation - multiple string literals in a row are concatenated
func (p *Parser) parsePropertyValue() ast2.Expression {
	firstExpr := p.parseExpression()
	if firstExpr == nil {
		return nil
	}

	// Check if this is a string literal followed by more string literals (implicit concatenation)
	// Only concatenate CSTR and LSTR tokens
	if !p.isStringLiteral(firstExpr) {
		return firstExpr
	}

	// Collect all consecutive string literals
	var stringParts []string

	// Add the first string value
	if strLit, ok := firstExpr.(*ast2.StringLiteral); ok {
		stringParts = append(stringParts, strLit.Value)
	}

	// Keep reading while we see string literals (across lines, potentially)
	for p.peekTokenIs(lexer.CSTR) || p.peekTokenIs(lexer.LSTR) {
		p.nextToken() // move to the string token

		if p.currentToken.Type == lexer.CSTR {
			strValue := strings.Trim(p.currentToken.Value, `"`)
			stringParts = append(stringParts, strValue)
		} else if p.currentToken.Type == lexer.LSTR {
			strValue := p.currentToken.Value
			if strings.HasPrefix(strValue, `{"`) && strings.HasSuffix(strValue, `"}`) {
				strValue = strValue[2 : len(strValue)-2]
			}
			stringParts = append(stringParts, strValue)
		}
	}

	// If only one string, return the original expression
	if len(stringParts) == 1 {
		return firstExpr
	}

	// Concatenate all strings with newlines (for probe .request properties)
	concatenated := stringParts[0]
	for i := 1; i < len(stringParts); i++ {
		concatenated += "\r\n" + stringParts[i]
	}

	// Return a single StringLiteral with the concatenated value
	return &ast2.StringLiteral{
		BaseNode: ast2.BaseNode{
			StartPos: firstExpr.Start(),
			EndPos:   p.currentToken.End,
		},
		Value: concatenated,
	}
}

// isStringLiteral checks if an expression is a string literal
func (p *Parser) isStringLiteral(expr ast2.Expression) bool {
	_, ok := expr.(*ast2.StringLiteral)
	return ok
}

// parseObjectExpression parses VCL object literals used in backend and probe definitions.
// Handles dot-notation properties (.url, .port) and supports both simple values
// and complex nested structures. Properties are separated by semicolons following
// VCL syntax conventions.
func (p *Parser) parseObjectExpression() *ast2.ObjectExpression {
	expr := &ast2.ObjectExpression{
		BaseNode: ast2.BaseNode{
			StartPos: p.currentToken.Start,
		},
	}

	p.nextToken() // move past '{'

	for !p.currentTokenIs(lexer.RBRACE) && !p.currentTokenIs(lexer.EOF) {
		if p.currentTokenIs(lexer.COMMENT) {
			p.nextToken()
			continue
		}

		// Skip empty lines or extra whitespace
		if p.currentTokenIs(lexer.SEMICOLON) {
			p.nextToken()
			continue
		}

		prop := &ast2.Property{
			BaseNode: ast2.BaseNode{
				StartPos: p.currentToken.Start,
			},
		}

		// Parse key - in VCL, object properties start with a dot (e.g., .url)
		if p.currentTokenIs(lexer.DOT) {
			p.nextToken() // move past '.'
			if !p.currentTokenIs(lexer.ID) {
				p.addError("expected property name after '.'")
				return nil
			}
			// Create an identifier for the property name (without the dot)
			prop.Key = &ast2.Identifier{
				BaseNode: ast2.BaseNode{
					StartPos: p.currentToken.Start,
					EndPos:   p.currentToken.End,
				},
				Name: p.currentToken.Value,
			}
		} else {
			// Fallback to parsing as a general expression
			prop.Key = p.parseExpression()
		}

		if !p.expectPeek(lexer.ASSIGN) {
			return nil
		}

		p.nextToken() // move past '='

		// VCL allows implicit string concatenation in property values
		// Multiple string literals in a row are concatenated
		prop.Value = p.parsePropertyValue()
		prop.EndPos = p.currentToken.End

		expr.Properties = append(expr.Properties, prop)

		// VCL uses semicolons to separate object properties
		if p.peekTokenIs(lexer.SEMICOLON) {
			p.nextToken() // move to ';'
			prop.EndPos = p.currentToken.End
			p.nextToken() // move past ';' to next property or '}'
		} else {
			p.nextToken() // move to next token if no semicolon
		}
	}

	if !p.currentTokenIs(lexer.RBRACE) {
		p.addError("expected '}' to close object expression")
		return nil
	}

	expr.EndPos = p.currentToken.End
	return expr
}

// parseTimeExpression parses time/duration expressions
func (p *Parser) parseTimeExpression() *ast2.TimeExpression {
	return &ast2.TimeExpression{
		BaseNode: ast2.BaseNode{
			StartPos: p.currentToken.Start,
			EndPos:   p.currentToken.End,
		},
		Value: p.currentToken.Value,
	}
}

// parseIPExpression parses IP address expressions
func (p *Parser) parseIPExpression() *ast2.IPExpression {
	return &ast2.IPExpression{
		BaseNode: ast2.BaseNode{
			StartPos: p.currentToken.Start,
			EndPos:   p.currentToken.End,
		},
		Value: p.currentToken.Value,
	}
}

// Helper functions to detect literal types

// isNumberFollowedByTimeUnit checks if current CNUM/FNUM token is followed by a time unit
func (p *Parser) isNumberFollowedByTimeUnit() bool {
	// Support both integer and float numbers
	if p.currentToken.Type != lexer.CNUM && p.currentToken.Type != lexer.FNUM {
		return false
	}

	// Check if next token is a time unit identifier
	if p.peekToken.Type != lexer.ID {
		return false
	}

	// Use the new duration validation utility
	return IsDurationUnit(p.peekToken.Value)
}

// parseTimeExpressionFromNumber parses time expressions from number + unit (e.g., "30" + "s")
func (p *Parser) parseTimeExpressionFromNumber() *ast2.TimeExpression {
	numberValue := p.currentToken.Value
	startPos := p.currentToken.Start

	p.nextToken() // move to time unit
	unitValue := p.currentToken.Value
	endPos := p.currentToken.End

	return &ast2.TimeExpression{
		BaseNode: ast2.BaseNode{
			StartPos: startPos,
			EndPos:   endPos,
		},
		Value: numberValue + unitValue, // combine "30" + "s" = "30s"
	}
}

// isTimeOrDurationLiteral checks if current token looks like a time/duration literal
func (p *Parser) isTimeOrDurationLiteral() bool {
	value := p.currentToken.Value
	if p.currentToken.Type != lexer.ID {
		return false
	}

	// Use the new duration validation utility to check for complete duration strings
	return ValidateDurationString(value)
}

// isIPLiteral checks if current token looks like an IP address
func (p *Parser) isIPLiteral() bool {
	value := p.currentToken.Value
	if p.currentToken.Type != lexer.ID {
		return false
	}

	// Simple check for IPv4 pattern (more sophisticated validation could be added)
	parts := strings.Split(value, ".")
	if len(parts) == 4 {
		for _, part := range parts {
			if _, err := strconv.Atoi(part); err != nil {
				return false
			}
		}
		return true
	}

	// Simple check for IPv6 (contains colons)
	return strings.Contains(value, ":")
}

// isNamedArgument checks if current token is the start of a named argument (ID followed by =)
func (p *Parser) isNamedArgument() bool {
	// Named arguments can be identifiers or keywords (e.g., probe=value, ssl=true)
	isValidParamName := p.currentTokenIs(lexer.ID) || p.isKeywordToken(p.currentToken.Type)
	return isValidParamName && p.peekTokenIs(lexer.ASSIGN)
}
